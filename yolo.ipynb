{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94429cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7c3c9da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo12n.pt to 'yolo12n.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5.34M/5.34M [00:00<00:00, 9.49MB/s]\n"
     ]
    }
   ],
   "source": [
    "#descargar el modelo YOLOv12\n",
    "model = YOLO('yolo12n.pt')  # Cargar el modelo YOLOv12 preentrenado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e83ece1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Objetos detectados: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n"
     ]
    }
   ],
   "source": [
    "objetos = model.names  # Obtener los nombres de los objetos detectados\n",
    "print(\"Objetos detectados:\", objetos)  # Imprimir los nombres de los objetos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34f5189c",
   "metadata": {},
   "outputs": [],
   "source": [
    "classNames = list(objetos.values())  # Obtener los nombres de las clases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc713a4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 (no detections), 194.0ms\n",
      "Speed: 4.3ms preprocess, 194.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 330.6ms\n",
      "Speed: 4.3ms preprocess, 330.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 226.6ms\n",
      "Speed: 3.2ms preprocess, 226.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 354.5ms\n",
      "Speed: 4.3ms preprocess, 354.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 232.8ms\n",
      "Speed: 5.6ms preprocess, 232.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 224.5ms\n",
      "Speed: 4.2ms preprocess, 224.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 207.3ms\n",
      "Speed: 5.4ms preprocess, 207.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 206.4ms\n",
      "Speed: 4.6ms preprocess, 206.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 266.9ms\n",
      "Speed: 6.1ms preprocess, 266.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 173.7ms\n",
      "Speed: 3.7ms preprocess, 173.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 262.4ms\n",
      "Speed: 2.9ms preprocess, 262.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 230.1ms\n",
      "Speed: 3.3ms preprocess, 230.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 277.9ms\n",
      "Speed: 4.4ms preprocess, 277.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 238.9ms\n",
      "Speed: 2.4ms preprocess, 238.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 223.2ms\n",
      "Speed: 4.0ms preprocess, 223.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 168.7ms\n",
      "Speed: 5.9ms preprocess, 168.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 127.6ms\n",
      "Speed: 1.5ms preprocess, 127.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 126.2ms\n",
      "Speed: 2.2ms preprocess, 126.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 112.6ms\n",
      "Speed: 2.6ms preprocess, 112.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 122.2ms\n",
      "Speed: 2.6ms preprocess, 122.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 114.5ms\n",
      "Speed: 2.7ms preprocess, 114.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 115.6ms\n",
      "Speed: 1.7ms preprocess, 115.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 121.5ms\n",
      "Speed: 2.4ms preprocess, 121.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 110.4ms\n",
      "Speed: 1.5ms preprocess, 110.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bird, 117.5ms\n",
      "Confianza: 0.31\n",
      "Clase: 14\n",
      "Confianza: 0.29\n",
      "Clase: 0\n",
      "Speed: 2.9ms preprocess, 117.5ms inference, 7.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 116.3ms\n",
      "Confianza: 0.47\n",
      "Clase: 0\n",
      "Confianza: 0.32\n",
      "Clase: 0\n",
      "Speed: 1.8ms preprocess, 116.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 125.2ms\n",
      "Confianza: 0.77\n",
      "Clase: 0\n",
      "Speed: 2.4ms preprocess, 125.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 remote, 106.3ms\n",
      "Confianza: 0.73\n",
      "Clase: 0\n",
      "Confianza: 0.26\n",
      "Clase: 65\n",
      "Speed: 1.5ms preprocess, 106.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 130.2ms\n",
      "Confianza: 0.81\n",
      "Clase: 0\n",
      "Speed: 1.6ms preprocess, 130.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 toothbrush, 115.6ms\n",
      "Confianza: 0.8\n",
      "Clase: 0\n",
      "Confianza: 0.54\n",
      "Clase: 79\n",
      "Speed: 2.8ms preprocess, 115.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 remote, 118.6ms\n",
      "Confianza: 0.84\n",
      "Clase: 0\n",
      "Confianza: 0.27\n",
      "Clase: 65\n",
      "Speed: 1.4ms preprocess, 118.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 102.4ms\n",
      "Confianza: 0.82\n",
      "Clase: 0\n",
      "Speed: 3.4ms preprocess, 102.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 remote, 115.4ms\n",
      "Confianza: 0.88\n",
      "Clase: 0\n",
      "Confianza: 0.29\n",
      "Clase: 65\n",
      "Speed: 1.5ms preprocess, 115.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 112.1ms\n",
      "Confianza: 0.89\n",
      "Clase: 0\n",
      "Speed: 1.5ms preprocess, 112.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 remote, 107.4ms\n",
      "Confianza: 0.89\n",
      "Clase: 0\n",
      "Confianza: 0.3\n",
      "Clase: 65\n",
      "Speed: 2.7ms preprocess, 107.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 remote, 121.6ms\n",
      "Confianza: 0.9\n",
      "Clase: 0\n",
      "Confianza: 0.55\n",
      "Clase: 65\n",
      "Speed: 6.7ms preprocess, 121.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 remote, 103.4ms\n",
      "Confianza: 0.9\n",
      "Clase: 0\n",
      "Confianza: 0.3\n",
      "Clase: 65\n",
      "Speed: 1.5ms preprocess, 103.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 115.2ms\n",
      "Confianza: 0.89\n",
      "Clase: 0\n",
      "Speed: 2.7ms preprocess, 115.2ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 remote, 112.2ms\n",
      "Confianza: 0.89\n",
      "Clase: 0\n",
      "Confianza: 0.31\n",
      "Clase: 65\n",
      "Speed: 2.6ms preprocess, 112.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 1 remote, 114.8ms\n",
      "Confianza: 0.89\n",
      "Clase: 0\n",
      "Confianza: 0.5\n",
      "Clase: 65\n",
      "Confianza: 0.3\n",
      "Clase: 56\n",
      "Speed: 2.5ms preprocess, 114.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 1 remote, 125.5ms\n",
      "Confianza: 0.9\n",
      "Clase: 0\n",
      "Confianza: 0.33\n",
      "Clase: 56\n",
      "Confianza: 0.29\n",
      "Clase: 65\n",
      "Speed: 1.7ms preprocess, 125.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 1 remote, 130.2ms\n",
      "Confianza: 0.9\n",
      "Clase: 0\n",
      "Confianza: 0.34\n",
      "Clase: 56\n",
      "Confianza: 0.28\n",
      "Clase: 65\n",
      "Speed: 3.6ms preprocess, 130.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 1 remote, 108.5ms\n",
      "Confianza: 0.9\n",
      "Clase: 0\n",
      "Confianza: 0.35\n",
      "Clase: 65\n",
      "Confianza: 0.3\n",
      "Clase: 56\n",
      "Speed: 1.5ms preprocess, 108.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 1 remote, 108.8ms\n",
      "Confianza: 0.9\n",
      "Clase: 0\n",
      "Confianza: 0.37\n",
      "Clase: 56\n",
      "Confianza: 0.32\n",
      "Clase: 65\n",
      "Speed: 1.7ms preprocess, 108.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 100.3ms\n",
      "Confianza: 0.86\n",
      "Clase: 0\n",
      "Speed: 3.8ms preprocess, 100.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 96.2ms\n",
      "Confianza: 0.84\n",
      "Clase: 0\n",
      "Speed: 1.8ms preprocess, 96.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 108.1ms\n",
      "Confianza: 0.87\n",
      "Clase: 0\n",
      "Speed: 3.5ms preprocess, 108.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 95.0ms\n",
      "Confianza: 0.87\n",
      "Clase: 0\n",
      "Speed: 1.3ms preprocess, 95.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 95.5ms\n",
      "Confianza: 0.86\n",
      "Clase: 0\n",
      "Speed: 2.6ms preprocess, 95.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 98.7ms\n",
      "Confianza: 0.85\n",
      "Clase: 0\n",
      "Speed: 1.7ms preprocess, 98.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 98.3ms\n",
      "Confianza: 0.87\n",
      "Clase: 0\n",
      "Speed: 2.9ms preprocess, 98.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 remote, 104.7ms\n",
      "Confianza: 0.89\n",
      "Clase: 0\n",
      "Confianza: 0.26\n",
      "Clase: 65\n",
      "Speed: 1.7ms preprocess, 104.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 99.1ms\n",
      "Confianza: 0.87\n",
      "Clase: 0\n",
      "Speed: 1.3ms preprocess, 99.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 remote, 111.4ms\n",
      "Confianza: 0.88\n",
      "Clase: 0\n",
      "Confianza: 0.26\n",
      "Clase: 65\n",
      "Speed: 1.3ms preprocess, 111.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 remote, 93.4ms\n",
      "Confianza: 0.88\n",
      "Clase: 0\n",
      "Confianza: 0.33\n",
      "Clase: 65\n",
      "Speed: 1.4ms preprocess, 93.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 97.0ms\n",
      "Confianza: 0.88\n",
      "Clase: 0\n",
      "Speed: 1.3ms preprocess, 97.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 95.6ms\n",
      "Confianza: 0.88\n",
      "Clase: 0\n",
      "Speed: 1.3ms preprocess, 95.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 105.0ms\n",
      "Confianza: 0.88\n",
      "Clase: 0\n",
      "Speed: 5.2ms preprocess, 105.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 102.5ms\n",
      "Confianza: 0.88\n",
      "Clase: 0\n",
      "Speed: 2.1ms preprocess, 102.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 remote, 110.1ms\n",
      "Confianza: 0.88\n",
      "Clase: 0\n",
      "Confianza: 0.26\n",
      "Clase: 65\n",
      "Speed: 2.8ms preprocess, 110.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 remote, 115.2ms\n",
      "Confianza: 0.92\n",
      "Clase: 0\n",
      "Confianza: 0.47\n",
      "Clase: 65\n",
      "Speed: 1.5ms preprocess, 115.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 remote, 94.3ms\n",
      "Confianza: 0.89\n",
      "Clase: 0\n",
      "Confianza: 0.28\n",
      "Clase: 65\n",
      "Speed: 2.1ms preprocess, 94.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 96.4ms\n",
      "Confianza: 0.88\n",
      "Clase: 0\n",
      "Speed: 1.6ms preprocess, 96.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 92.8ms\n",
      "Confianza: 0.88\n",
      "Clase: 0\n",
      "Speed: 1.2ms preprocess, 92.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 98.1ms\n",
      "Confianza: 0.88\n",
      "Clase: 0\n",
      "Speed: 1.5ms preprocess, 98.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 97.7ms\n",
      "Confianza: 0.88\n",
      "Clase: 0\n",
      "Speed: 1.9ms preprocess, 97.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 94.3ms\n",
      "Confianza: 0.88\n",
      "Clase: 0\n",
      "Speed: 1.6ms preprocess, 94.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 88.1ms\n",
      "Confianza: 0.88\n",
      "Clase: 0\n",
      "Speed: 2.1ms preprocess, 88.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 remote, 94.3ms\n",
      "Confianza: 0.87\n",
      "Clase: 0\n",
      "Confianza: 0.29\n",
      "Clase: 65\n",
      "Speed: 3.2ms preprocess, 94.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 96.7ms\n",
      "Confianza: 0.87\n",
      "Clase: 0\n",
      "Speed: 1.5ms preprocess, 96.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 93.6ms\n",
      "Confianza: 0.88\n",
      "Clase: 0\n",
      "Speed: 1.4ms preprocess, 93.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 94.8ms\n",
      "Confianza: 0.89\n",
      "Clase: 0\n",
      "Speed: 1.4ms preprocess, 94.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 92.4ms\n",
      "Confianza: 0.88\n",
      "Clase: 0\n",
      "Speed: 3.8ms preprocess, 92.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 91.8ms\n",
      "Confianza: 0.88\n",
      "Clase: 0\n",
      "Speed: 2.2ms preprocess, 91.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 93.8ms\n",
      "Confianza: 0.9\n",
      "Clase: 0\n",
      "Speed: 1.5ms preprocess, 93.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 96.5ms\n",
      "Confianza: 0.9\n",
      "Clase: 0\n",
      "Speed: 1.9ms preprocess, 96.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 93.8ms\n",
      "Confianza: 0.91\n",
      "Clase: 0\n",
      "Speed: 1.4ms preprocess, 93.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 101.6ms\n",
      "Confianza: 0.91\n",
      "Clase: 0\n",
      "Speed: 1.7ms preprocess, 101.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 99.2ms\n",
      "Confianza: 0.92\n",
      "Clase: 0\n",
      "Speed: 1.5ms preprocess, 99.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 98.7ms\n",
      "Confianza: 0.92\n",
      "Clase: 0\n",
      "Speed: 1.3ms preprocess, 98.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 96.3ms\n",
      "Confianza: 0.9\n",
      "Clase: 0\n",
      "Speed: 2.3ms preprocess, 96.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 94.0ms\n",
      "Confianza: 0.86\n",
      "Clase: 0\n",
      "Speed: 1.4ms preprocess, 94.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 92.8ms\n",
      "Confianza: 0.88\n",
      "Clase: 0\n",
      "Confianza: 0.46\n",
      "Clase: 0\n",
      "Speed: 1.6ms preprocess, 92.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 110.6ms\n",
      "Confianza: 0.87\n",
      "Clase: 0\n",
      "Confianza: 0.54\n",
      "Clase: 0\n",
      "Speed: 1.2ms preprocess, 110.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 94.1ms\n",
      "Confianza: 0.91\n",
      "Clase: 0\n",
      "Speed: 2.6ms preprocess, 94.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 98.6ms\n",
      "Confianza: 0.91\n",
      "Clase: 0\n",
      "Speed: 2.1ms preprocess, 98.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 92.1ms\n",
      "Confianza: 0.9\n",
      "Clase: 0\n",
      "Speed: 1.6ms preprocess, 92.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 99.4ms\n",
      "Confianza: 0.9\n",
      "Clase: 0\n",
      "Confianza: 0.53\n",
      "Clase: 67\n",
      "Speed: 2.5ms preprocess, 99.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 remote, 1 cell phone, 97.4ms\n",
      "Confianza: 0.86\n",
      "Clase: 0\n",
      "Confianza: 0.4\n",
      "Clase: 67\n",
      "Confianza: 0.35\n",
      "Clase: 65\n",
      "Speed: 1.3ms preprocess, 97.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 remote, 1 cell phone, 90.7ms\n",
      "Confianza: 0.83\n",
      "Clase: 0\n",
      "Confianza: 0.36\n",
      "Clase: 67\n",
      "Confianza: 0.31\n",
      "Clase: 65\n",
      "Speed: 1.7ms preprocess, 90.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 90.3ms\n",
      "Confianza: 0.89\n",
      "Clase: 0\n",
      "Confianza: 0.47\n",
      "Clase: 0\n",
      "Speed: 2.4ms preprocess, 90.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 cell phone, 96.6ms\n",
      "Confianza: 0.9\n",
      "Clase: 0\n",
      "Confianza: 0.46\n",
      "Clase: 0\n",
      "Confianza: 0.27\n",
      "Clase: 67\n",
      "Speed: 1.5ms preprocess, 96.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 93.2ms\n",
      "Confianza: 0.9\n",
      "Clase: 0\n",
      "Speed: 1.2ms preprocess, 93.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 94.9ms\n",
      "Confianza: 0.9\n",
      "Clase: 0\n",
      "Speed: 1.6ms preprocess, 94.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 100.7ms\n",
      "Confianza: 0.9\n",
      "Clase: 0\n",
      "Confianza: 0.36\n",
      "Clase: 56\n",
      "Speed: 2.2ms preprocess, 100.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 96.7ms\n",
      "Confianza: 0.9\n",
      "Clase: 0\n",
      "Speed: 2.1ms preprocess, 96.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 96.3ms\n",
      "Confianza: 0.89\n",
      "Clase: 0\n",
      "Speed: 3.9ms preprocess, 96.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 92.7ms\n",
      "Confianza: 0.9\n",
      "Clase: 0\n",
      "Speed: 1.4ms preprocess, 92.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 95.0ms\n",
      "Confianza: 0.92\n",
      "Clase: 0\n",
      "Speed: 1.9ms preprocess, 95.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 91.0ms\n",
      "Confianza: 0.92\n",
      "Clase: 0\n",
      "Confianza: 0.32\n",
      "Clase: 62\n",
      "Speed: 1.3ms preprocess, 91.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 140.4ms\n",
      "Confianza: 0.91\n",
      "Clase: 0\n",
      "Speed: 2.4ms preprocess, 140.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 101.4ms\n",
      "Confianza: 0.91\n",
      "Clase: 0\n",
      "Confianza: 0.37\n",
      "Clase: 62\n",
      "Speed: 4.6ms preprocess, 101.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 110.5ms\n",
      "Confianza: 0.91\n",
      "Clase: 0\n",
      "Confianza: 0.33\n",
      "Clase: 56\n",
      "Speed: 3.3ms preprocess, 110.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 92.5ms\n",
      "Confianza: 0.91\n",
      "Clase: 0\n",
      "Confianza: 0.63\n",
      "Clase: 62\n",
      "Speed: 1.6ms preprocess, 92.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 1 tv, 98.7ms\n",
      "Confianza: 0.91\n",
      "Clase: 0\n",
      "Confianza: 0.71\n",
      "Clase: 62\n",
      "Confianza: 0.28\n",
      "Clase: 39\n",
      "Speed: 1.8ms preprocess, 98.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 93.6ms\n",
      "Confianza: 0.91\n",
      "Clase: 0\n",
      "Confianza: 0.26\n",
      "Clase: 62\n",
      "Speed: 1.7ms preprocess, 93.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 87.8ms\n",
      "Confianza: 0.91\n",
      "Clase: 0\n",
      "Confianza: 0.29\n",
      "Clase: 39\n",
      "Speed: 2.0ms preprocess, 87.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 1 tv, 91.6ms\n",
      "Confianza: 0.91\n",
      "Clase: 0\n",
      "Confianza: 0.66\n",
      "Clase: 62\n",
      "Confianza: 0.27\n",
      "Clase: 39\n",
      "Speed: 2.5ms preprocess, 91.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 92.5ms\n",
      "Confianza: 0.92\n",
      "Clase: 0\n",
      "Confianza: 0.35\n",
      "Clase: 62\n",
      "Speed: 1.4ms preprocess, 92.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 105.7ms\n",
      "Confianza: 0.91\n",
      "Clase: 0\n",
      "Speed: 1.4ms preprocess, 105.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 96.1ms\n",
      "Confianza: 0.91\n",
      "Clase: 0\n",
      "Speed: 1.7ms preprocess, 96.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 96.0ms\n",
      "Confianza: 0.91\n",
      "Clase: 0\n",
      "Confianza: 0.47\n",
      "Clase: 62\n",
      "Speed: 2.3ms preprocess, 96.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 89.4ms\n",
      "Confianza: 0.91\n",
      "Clase: 0\n",
      "Confianza: 0.49\n",
      "Clase: 62\n",
      "Speed: 1.5ms preprocess, 89.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 94.3ms\n",
      "Confianza: 0.91\n",
      "Clase: 0\n",
      "Confianza: 0.55\n",
      "Clase: 62\n",
      "Speed: 3.5ms preprocess, 94.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 1 tv, 89.6ms\n",
      "Confianza: 0.92\n",
      "Clase: 0\n",
      "Confianza: 0.43\n",
      "Clase: 62\n",
      "Confianza: 0.3\n",
      "Clase: 39\n",
      "Speed: 1.2ms preprocess, 89.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 92.5ms\n",
      "Confianza: 0.92\n",
      "Clase: 0\n",
      "Confianza: 0.6\n",
      "Clase: 62\n",
      "Speed: 1.9ms preprocess, 92.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 93.3ms\n",
      "Confianza: 0.92\n",
      "Clase: 0\n",
      "Confianza: 0.63\n",
      "Clase: 62\n",
      "Speed: 1.6ms preprocess, 93.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 89.1ms\n",
      "Confianza: 0.92\n",
      "Clase: 0\n",
      "Speed: 2.1ms preprocess, 89.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 97.1ms\n",
      "Confianza: 0.91\n",
      "Clase: 0\n",
      "Speed: 1.8ms preprocess, 97.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 91.4ms\n",
      "Confianza: 0.92\n",
      "Clase: 0\n",
      "Speed: 1.5ms preprocess, 91.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 94.2ms\n",
      "Confianza: 0.92\n",
      "Clase: 0\n",
      "Confianza: 0.27\n",
      "Clase: 39\n",
      "Speed: 2.3ms preprocess, 94.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 90.9ms\n",
      "Confianza: 0.91\n",
      "Clase: 0\n",
      "Speed: 1.9ms preprocess, 90.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 87.4ms\n",
      "Confianza: 0.91\n",
      "Clase: 0\n",
      "Speed: 2.0ms preprocess, 87.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 94.3ms\n",
      "Confianza: 0.91\n",
      "Clase: 0\n",
      "Speed: 1.4ms preprocess, 94.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 91.2ms\n",
      "Confianza: 0.91\n",
      "Clase: 0\n",
      "Speed: 2.5ms preprocess, 91.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 93.0ms\n",
      "Confianza: 0.9\n",
      "Clase: 0\n",
      "Speed: 1.4ms preprocess, 93.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 90.7ms\n",
      "Confianza: 0.91\n",
      "Clase: 0\n",
      "Speed: 1.6ms preprocess, 90.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 101.9ms\n",
      "Confianza: 0.91\n",
      "Clase: 0\n",
      "Confianza: 0.27\n",
      "Clase: 39\n",
      "Speed: 3.2ms preprocess, 101.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 95.8ms\n",
      "Confianza: 0.9\n",
      "Clase: 0\n",
      "Confianza: 0.29\n",
      "Clase: 39\n",
      "Speed: 1.3ms preprocess, 95.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 93.4ms\n",
      "Confianza: 0.91\n",
      "Clase: 0\n",
      "Speed: 1.7ms preprocess, 93.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 95.5ms\n",
      "Confianza: 0.91\n",
      "Clase: 0\n",
      "Confianza: 0.26\n",
      "Clase: 39\n",
      "Speed: 1.5ms preprocess, 95.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 95.4ms\n",
      "Confianza: 0.9\n",
      "Clase: 0\n",
      "Confianza: 0.29\n",
      "Clase: 39\n",
      "Speed: 1.4ms preprocess, 95.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 93.1ms\n",
      "Confianza: 0.9\n",
      "Clase: 0\n",
      "Confianza: 0.33\n",
      "Clase: 39\n",
      "Speed: 1.6ms preprocess, 93.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 97.2ms\n",
      "Confianza: 0.89\n",
      "Clase: 0\n",
      "Confianza: 0.26\n",
      "Clase: 39\n",
      "Speed: 2.0ms preprocess, 97.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 111.9ms\n",
      "Confianza: 0.91\n",
      "Clase: 0\n",
      "Speed: 2.8ms preprocess, 111.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 91.6ms\n",
      "Confianza: 0.91\n",
      "Clase: 0\n",
      "Confianza: 0.27\n",
      "Clase: 39\n",
      "Speed: 1.2ms preprocess, 91.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 113.0ms\n",
      "Confianza: 0.91\n",
      "Clase: 0\n",
      "Speed: 1.4ms preprocess, 113.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 94.0ms\n",
      "Confianza: 0.91\n",
      "Clase: 0\n",
      "Speed: 1.3ms preprocess, 94.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 97.8ms\n",
      "Confianza: 0.91\n",
      "Clase: 0\n",
      "Speed: 1.8ms preprocess, 97.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 96.4ms\n",
      "Confianza: 0.91\n",
      "Clase: 0\n",
      "Speed: 1.4ms preprocess, 96.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 97.7ms\n",
      "Confianza: 0.91\n",
      "Clase: 0\n",
      "Confianza: 0.3\n",
      "Clase: 39\n",
      "Speed: 1.7ms preprocess, 97.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 92.2ms\n",
      "Confianza: 0.91\n",
      "Clase: 0\n",
      "Confianza: 0.26\n",
      "Clase: 39\n",
      "Speed: 1.5ms preprocess, 92.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 91.6ms\n",
      "Confianza: 0.9\n",
      "Clase: 0\n",
      "Confianza: 0.27\n",
      "Clase: 39\n",
      "Speed: 1.6ms preprocess, 91.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 98.2ms\n",
      "Confianza: 0.91\n",
      "Clase: 0\n",
      "Confianza: 0.27\n",
      "Clase: 39\n",
      "Speed: 3.2ms preprocess, 98.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 97.0ms\n",
      "Confianza: 0.9\n",
      "Clase: 0\n",
      "Speed: 2.1ms preprocess, 97.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 113.7ms\n",
      "Confianza: 0.91\n",
      "Clase: 0\n",
      "Confianza: 0.26\n",
      "Clase: 39\n",
      "Speed: 1.5ms preprocess, 113.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 97.0ms\n",
      "Confianza: 0.91\n",
      "Clase: 0\n",
      "Confianza: 0.32\n",
      "Clase: 39\n",
      "Speed: 1.9ms preprocess, 97.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 105.8ms\n",
      "Confianza: 0.91\n",
      "Clase: 0\n",
      "Confianza: 0.31\n",
      "Clase: 39\n",
      "Speed: 1.3ms preprocess, 105.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 106.3ms\n",
      "Confianza: 0.9\n",
      "Clase: 0\n",
      "Confianza: 0.31\n",
      "Clase: 39\n",
      "Speed: 1.7ms preprocess, 106.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 103.8ms\n",
      "Confianza: 0.91\n",
      "Clase: 0\n",
      "Speed: 2.7ms preprocess, 103.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 104.4ms\n",
      "Confianza: 0.9\n",
      "Clase: 0\n",
      "Speed: 2.2ms preprocess, 104.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 117.1ms\n",
      "Confianza: 0.91\n",
      "Clase: 0\n",
      "Speed: 2.7ms preprocess, 117.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 98.9ms\n",
      "Confianza: 0.91\n",
      "Clase: 0\n",
      "Speed: 1.9ms preprocess, 98.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 99.1ms\n",
      "Confianza: 0.91\n",
      "Clase: 0\n",
      "Confianza: 0.28\n",
      "Clase: 56\n",
      "Speed: 4.3ms preprocess, 99.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 97.2ms\n",
      "Confianza: 0.88\n",
      "Clase: 0\n",
      "Speed: 1.4ms preprocess, 97.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 93.1ms\n",
      "Confianza: 0.86\n",
      "Clase: 0\n",
      "Speed: 1.5ms preprocess, 93.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 94.8ms\n",
      "Confianza: 0.79\n",
      "Clase: 0\n",
      "Confianza: 0.3\n",
      "Clase: 56\n",
      "Speed: 1.6ms preprocess, 94.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 88.9ms\n",
      "Confianza: 0.67\n",
      "Clase: 0\n",
      "Speed: 2.0ms preprocess, 88.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 toothbrushs, 99.4ms\n",
      "Confianza: 0.81\n",
      "Clase: 0\n",
      "Confianza: 0.45\n",
      "Clase: 79\n",
      "Confianza: 0.36\n",
      "Clase: 79\n",
      "Speed: 2.7ms preprocess, 99.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 toothbrushs, 88.2ms\n",
      "Confianza: 0.86\n",
      "Clase: 0\n",
      "Confianza: 0.46\n",
      "Clase: 79\n",
      "Confianza: 0.33\n",
      "Clase: 79\n",
      "Speed: 1.3ms preprocess, 88.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 3 toothbrushs, 96.2ms\n",
      "Confianza: 0.67\n",
      "Clase: 0\n",
      "Confianza: 0.49\n",
      "Clase: 79\n",
      "Confianza: 0.42\n",
      "Clase: 79\n",
      "Confianza: 0.39\n",
      "Clase: 79\n",
      "Speed: 1.4ms preprocess, 96.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 toothbrush, 97.9ms\n",
      "Confianza: 0.66\n",
      "Clase: 0\n",
      "Confianza: 0.5\n",
      "Clase: 79\n",
      "Speed: 1.5ms preprocess, 97.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 3 toothbrushs, 105.3ms\n",
      "Confianza: 0.61\n",
      "Clase: 0\n",
      "Confianza: 0.43\n",
      "Clase: 79\n",
      "Confianza: 0.39\n",
      "Clase: 79\n",
      "Confianza: 0.26\n",
      "Clase: 79\n",
      "Speed: 1.4ms preprocess, 105.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 toothbrushs, 95.7ms\n",
      "Confianza: 0.66\n",
      "Clase: 0\n",
      "Confianza: 0.36\n",
      "Clase: 79\n",
      "Confianza: 0.3\n",
      "Clase: 79\n",
      "Speed: 2.3ms preprocess, 95.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 toothbrushs, 96.1ms\n",
      "Confianza: 0.69\n",
      "Clase: 0\n",
      "Confianza: 0.47\n",
      "Clase: 79\n",
      "Confianza: 0.26\n",
      "Clase: 79\n",
      "Speed: 2.4ms preprocess, 96.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 toothbrush, 90.5ms\n",
      "Confianza: 0.75\n",
      "Clase: 0\n",
      "Confianza: 0.4\n",
      "Clase: 79\n",
      "Speed: 1.2ms preprocess, 90.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 toothbrush, 99.1ms\n",
      "Confianza: 0.78\n",
      "Clase: 0\n",
      "Confianza: 0.43\n",
      "Clase: 79\n",
      "Speed: 1.5ms preprocess, 99.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 toothbrush, 93.3ms\n",
      "Confianza: 0.77\n",
      "Clase: 0\n",
      "Confianza: 0.32\n",
      "Clase: 79\n",
      "Speed: 1.6ms preprocess, 93.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 toothbrush, 94.9ms\n",
      "Confianza: 0.7\n",
      "Clase: 0\n",
      "Confianza: 0.3\n",
      "Clase: 79\n",
      "Speed: 2.2ms preprocess, 94.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 91.7ms\n",
      "Confianza: 0.7\n",
      "Clase: 0\n",
      "Speed: 1.6ms preprocess, 91.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 toothbrushs, 101.0ms\n",
      "Confianza: 0.7\n",
      "Clase: 0\n",
      "Confianza: 0.27\n",
      "Clase: 79\n",
      "Confianza: 0.27\n",
      "Clase: 79\n",
      "Speed: 1.7ms preprocess, 101.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 92.3ms\n",
      "Confianza: 0.89\n",
      "Clase: 0\n",
      "Confianza: 0.31\n",
      "Clase: 56\n",
      "Speed: 1.4ms preprocess, 92.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 94.8ms\n",
      "Confianza: 0.88\n",
      "Clase: 0\n",
      "Speed: 1.9ms preprocess, 94.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 90.4ms\n",
      "Confianza: 0.89\n",
      "Clase: 0\n",
      "Speed: 1.2ms preprocess, 90.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 90.6ms\n",
      "Confianza: 0.88\n",
      "Clase: 0\n",
      "Confianza: 0.29\n",
      "Clase: 39\n",
      "Speed: 2.1ms preprocess, 90.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 89.8ms\n",
      "Confianza: 0.88\n",
      "Clase: 0\n",
      "Confianza: 0.36\n",
      "Clase: 39\n",
      "Speed: 1.7ms preprocess, 89.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 93.6ms\n",
      "Confianza: 0.87\n",
      "Clase: 0\n",
      "Confianza: 0.38\n",
      "Clase: 39\n",
      "Speed: 1.2ms preprocess, 93.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 89.5ms\n",
      "Confianza: 0.86\n",
      "Clase: 0\n",
      "Confianza: 0.29\n",
      "Clase: 39\n",
      "Speed: 1.6ms preprocess, 89.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 144.9ms\n",
      "Confianza: 0.74\n",
      "Clase: 0\n",
      "Confianza: 0.26\n",
      "Clase: 39\n",
      "Speed: 1.5ms preprocess, 144.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 147.8ms\n",
      "Confianza: 0.86\n",
      "Clase: 0\n",
      "Confianza: 0.38\n",
      "Clase: 39\n",
      "Speed: 2.6ms preprocess, 147.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 127.0ms\n",
      "Confianza: 0.9\n",
      "Clase: 0\n",
      "Speed: 1.7ms preprocess, 127.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 1 toothbrush, 102.4ms\n",
      "Confianza: 0.89\n",
      "Clase: 0\n",
      "Confianza: 0.29\n",
      "Clase: 39\n",
      "Confianza: 0.26\n",
      "Clase: 79\n",
      "Speed: 1.9ms preprocess, 102.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 1 toothbrush, 97.0ms\n",
      "Confianza: 0.89\n",
      "Clase: 0\n",
      "Confianza: 0.39\n",
      "Clase: 79\n",
      "Confianza: 0.3\n",
      "Clase: 39\n",
      "Speed: 1.8ms preprocess, 97.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 1 cup, 3 toothbrushs, 89.6ms\n",
      "Confianza: 0.88\n",
      "Clase: 0\n",
      "Confianza: 0.4\n",
      "Clase: 79\n",
      "Confianza: 0.39\n",
      "Clase: 39\n",
      "Confianza: 0.38\n",
      "Clase: 79\n",
      "Confianza: 0.36\n",
      "Clase: 79\n",
      "Confianza: 0.3\n",
      "Clase: 41\n",
      "Speed: 3.2ms preprocess, 89.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 1 toothbrush, 95.1ms\n",
      "Confianza: 0.89\n",
      "Clase: 0\n",
      "Confianza: 0.4\n",
      "Clase: 39\n",
      "Confianza: 0.4\n",
      "Clase: 79\n",
      "Speed: 2.1ms preprocess, 95.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 3 toothbrushs, 89.7ms\n",
      "Confianza: 0.89\n",
      "Clase: 0\n",
      "Confianza: 0.38\n",
      "Clase: 79\n",
      "Confianza: 0.34\n",
      "Clase: 39\n",
      "Confianza: 0.34\n",
      "Clase: 79\n",
      "Confianza: 0.27\n",
      "Clase: 79\n",
      "Speed: 1.3ms preprocess, 89.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 3 toothbrushs, 96.0ms\n",
      "Confianza: 0.87\n",
      "Clase: 0\n",
      "Confianza: 0.37\n",
      "Clase: 79\n",
      "Confianza: 0.35\n",
      "Clase: 79\n",
      "Confianza: 0.28\n",
      "Clase: 39\n",
      "Confianza: 0.28\n",
      "Clase: 79\n",
      "Speed: 3.0ms preprocess, 96.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 2 toothbrushs, 107.4ms\n",
      "Confianza: 0.88\n",
      "Clase: 0\n",
      "Confianza: 0.45\n",
      "Clase: 79\n",
      "Confianza: 0.34\n",
      "Clase: 39\n",
      "Confianza: 0.31\n",
      "Clase: 79\n",
      "Speed: 2.6ms preprocess, 107.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 2 toothbrushs, 98.8ms\n",
      "Confianza: 0.89\n",
      "Clase: 0\n",
      "Confianza: 0.38\n",
      "Clase: 79\n",
      "Confianza: 0.32\n",
      "Clase: 39\n",
      "Confianza: 0.29\n",
      "Clase: 79\n",
      "Speed: 1.8ms preprocess, 98.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 104.1ms\n",
      "Confianza: 0.91\n",
      "Clase: 0\n",
      "Confianza: 0.38\n",
      "Clase: 39\n",
      "Speed: 2.5ms preprocess, 104.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 94.6ms\n",
      "Confianza: 0.91\n",
      "Clase: 0\n",
      "Confianza: 0.33\n",
      "Clase: 39\n",
      "Speed: 2.2ms preprocess, 94.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 92.3ms\n",
      "Confianza: 0.91\n",
      "Clase: 0\n",
      "Confianza: 0.36\n",
      "Clase: 39\n",
      "Speed: 2.0ms preprocess, 92.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 bottles, 95.6ms\n",
      "Confianza: 0.92\n",
      "Clase: 0\n",
      "Confianza: 0.35\n",
      "Clase: 39\n",
      "Confianza: 0.26\n",
      "Clase: 39\n",
      "Speed: 1.8ms preprocess, 95.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 90.7ms\n",
      "Confianza: 0.92\n",
      "Clase: 0\n",
      "Confianza: 0.37\n",
      "Clase: 39\n",
      "Speed: 1.3ms preprocess, 90.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 99.6ms\n",
      "Confianza: 0.91\n",
      "Clase: 0\n",
      "Confianza: 0.36\n",
      "Clase: 39\n",
      "Speed: 1.9ms preprocess, 99.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 95.6ms\n",
      "Confianza: 0.93\n",
      "Clase: 0\n",
      "Confianza: 0.35\n",
      "Clase: 39\n",
      "Speed: 3.3ms preprocess, 95.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 87.9ms\n",
      "Confianza: 0.91\n",
      "Clase: 0\n",
      "Confianza: 0.34\n",
      "Clase: 39\n",
      "Speed: 3.1ms preprocess, 87.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 101.8ms\n",
      "Confianza: 0.92\n",
      "Clase: 0\n",
      "Confianza: 0.33\n",
      "Clase: 39\n",
      "Speed: 1.5ms preprocess, 101.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 94.2ms\n",
      "Confianza: 0.91\n",
      "Clase: 0\n",
      "Confianza: 0.32\n",
      "Clase: 39\n",
      "Speed: 1.4ms preprocess, 94.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 96.3ms\n",
      "Confianza: 0.91\n",
      "Clase: 0\n",
      "Confianza: 0.36\n",
      "Clase: 39\n",
      "Speed: 1.6ms preprocess, 96.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 108.0ms\n",
      "Confianza: 0.91\n",
      "Clase: 0\n",
      "Confianza: 0.42\n",
      "Clase: 39\n",
      "Speed: 1.3ms preprocess, 108.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 108.7ms\n",
      "Confianza: 0.9\n",
      "Clase: 0\n",
      "Confianza: 0.36\n",
      "Clase: 39\n",
      "Speed: 1.3ms preprocess, 108.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 105.4ms\n",
      "Confianza: 0.89\n",
      "Clase: 0\n",
      "Confianza: 0.37\n",
      "Clase: 39\n",
      "Speed: 1.6ms preprocess, 105.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 105.7ms\n",
      "Confianza: 0.9\n",
      "Clase: 0\n",
      "Confianza: 0.37\n",
      "Clase: 39\n",
      "Speed: 1.9ms preprocess, 105.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 101.2ms\n",
      "Confianza: 0.91\n",
      "Clase: 0\n",
      "Confianza: 0.37\n",
      "Clase: 39\n",
      "Speed: 1.6ms preprocess, 101.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 101.0ms\n",
      "Confianza: 0.88\n",
      "Clase: 0\n",
      "Confianza: 0.39\n",
      "Clase: 39\n",
      "Speed: 1.2ms preprocess, 101.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 115.6ms\n",
      "Confianza: 0.88\n",
      "Clase: 0\n",
      "Confianza: 0.41\n",
      "Clase: 39\n",
      "Speed: 1.3ms preprocess, 115.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 155.8ms\n",
      "Confianza: 0.88\n",
      "Clase: 0\n",
      "Confianza: 0.41\n",
      "Clase: 39\n",
      "Speed: 1.3ms preprocess, 155.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 bottles, 144.5ms\n",
      "Confianza: 0.9\n",
      "Clase: 0\n",
      "Confianza: 0.43\n",
      "Clase: 39\n",
      "Confianza: 0.26\n",
      "Clase: 39\n",
      "Speed: 4.2ms preprocess, 144.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 116.3ms\n",
      "Confianza: 0.91\n",
      "Clase: 0\n",
      "Confianza: 0.44\n",
      "Clase: 39\n",
      "Speed: 2.4ms preprocess, 116.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 148.0ms\n",
      "Confianza: 0.9\n",
      "Clase: 0\n",
      "Confianza: 0.4\n",
      "Clase: 39\n",
      "Speed: 1.9ms preprocess, 148.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 120.9ms\n",
      "Confianza: 0.9\n",
      "Clase: 0\n",
      "Confianza: 0.38\n",
      "Clase: 39\n",
      "Speed: 2.6ms preprocess, 120.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 116.2ms\n",
      "Confianza: 0.9\n",
      "Clase: 0\n",
      "Confianza: 0.35\n",
      "Clase: 39\n",
      "Speed: 1.6ms preprocess, 116.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 109.2ms\n",
      "Confianza: 0.89\n",
      "Clase: 0\n",
      "Confianza: 0.37\n",
      "Clase: 39\n",
      "Speed: 1.5ms preprocess, 109.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 158.8ms\n",
      "Confianza: 0.89\n",
      "Clase: 0\n",
      "Confianza: 0.34\n",
      "Clase: 39\n",
      "Speed: 2.0ms preprocess, 158.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 196.0ms\n",
      "Confianza: 0.85\n",
      "Clase: 0\n",
      "Confianza: 0.26\n",
      "Clase: 39\n",
      "Speed: 14.4ms preprocess, 196.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 138.7ms\n",
      "Confianza: 0.65\n",
      "Clase: 0\n",
      "Confianza: 0.49\n",
      "Clase: 0\n",
      "Speed: 2.1ms preprocess, 138.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 157.4ms\n",
      "Confianza: 0.84\n",
      "Clase: 0\n",
      "Speed: 1.7ms preprocess, 157.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 138.9ms\n",
      "Confianza: 0.9\n",
      "Clase: 0\n",
      "Speed: 2.3ms preprocess, 138.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 151.6ms\n",
      "Confianza: 0.87\n",
      "Clase: 0\n",
      "Speed: 1.8ms preprocess, 151.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 141.5ms\n",
      "Confianza: 0.87\n",
      "Clase: 0\n",
      "Speed: 1.9ms preprocess, 141.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 147.5ms\n",
      "Confianza: 0.88\n",
      "Clase: 0\n",
      "Speed: 2.3ms preprocess, 147.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 157.8ms\n",
      "Confianza: 0.87\n",
      "Clase: 0\n",
      "Speed: 3.2ms preprocess, 157.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 162.5ms\n",
      "Confianza: 0.86\n",
      "Clase: 0\n",
      "Confianza: 0.27\n",
      "Clase: 39\n",
      "Speed: 2.5ms preprocess, 162.5ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 168.0ms\n",
      "Confianza: 0.84\n",
      "Clase: 0\n",
      "Confianza: 0.32\n",
      "Clase: 39\n",
      "Speed: 3.3ms preprocess, 168.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 153.8ms\n",
      "Confianza: 0.86\n",
      "Clase: 0\n",
      "Confianza: 0.27\n",
      "Clase: 39\n",
      "Speed: 1.6ms preprocess, 153.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 139.9ms\n",
      "Confianza: 0.87\n",
      "Clase: 0\n",
      "Confianza: 0.26\n",
      "Clase: 39\n",
      "Speed: 3.4ms preprocess, 139.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 145.7ms\n",
      "Confianza: 0.88\n",
      "Clase: 0\n",
      "Confianza: 0.3\n",
      "Clase: 39\n",
      "Speed: 2.1ms preprocess, 145.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 153.4ms\n",
      "Confianza: 0.89\n",
      "Clase: 0\n",
      "Confianza: 0.3\n",
      "Clase: 39\n",
      "Speed: 2.0ms preprocess, 153.4ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 131.0ms\n",
      "Confianza: 0.86\n",
      "Clase: 0\n",
      "Confianza: 0.3\n",
      "Clase: 39\n",
      "Speed: 3.5ms preprocess, 131.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 131.7ms\n",
      "Confianza: 0.92\n",
      "Clase: 0\n",
      "Confianza: 0.32\n",
      "Clase: 39\n",
      "Speed: 2.4ms preprocess, 131.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 116.0ms\n",
      "Confianza: 0.93\n",
      "Clase: 0\n",
      "Confianza: 0.31\n",
      "Clase: 39\n",
      "Speed: 1.6ms preprocess, 116.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 114.3ms\n",
      "Confianza: 0.92\n",
      "Clase: 0\n",
      "Confianza: 0.33\n",
      "Clase: 39\n",
      "Speed: 3.9ms preprocess, 114.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 113.1ms\n",
      "Confianza: 0.93\n",
      "Clase: 0\n",
      "Confianza: 0.32\n",
      "Clase: 39\n",
      "Speed: 2.6ms preprocess, 113.1ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 170.9ms\n",
      "Confianza: 0.92\n",
      "Clase: 0\n",
      "Confianza: 0.3\n",
      "Clase: 39\n",
      "Speed: 1.8ms preprocess, 170.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 137.6ms\n",
      "Confianza: 0.9\n",
      "Clase: 0\n",
      "Confianza: 0.31\n",
      "Clase: 39\n",
      "Speed: 3.7ms preprocess, 137.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 130.3ms\n",
      "Confianza: 0.9\n",
      "Clase: 0\n",
      "Confianza: 0.28\n",
      "Clase: 39\n",
      "Speed: 2.4ms preprocess, 130.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 176.6ms\n",
      "Confianza: 0.9\n",
      "Clase: 0\n",
      "Speed: 1.7ms preprocess, 176.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 153.8ms\n",
      "Confianza: 0.86\n",
      "Clase: 0\n",
      "Confianza: 0.28\n",
      "Clase: 39\n",
      "Speed: 2.2ms preprocess, 153.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 144.3ms\n",
      "Confianza: 0.89\n",
      "Clase: 0\n",
      "Confianza: 0.3\n",
      "Clase: 39\n",
      "Speed: 2.2ms preprocess, 144.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 143.6ms\n",
      "Confianza: 0.93\n",
      "Clase: 0\n",
      "Confianza: 0.28\n",
      "Clase: 39\n",
      "Speed: 1.6ms preprocess, 143.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 164.8ms\n",
      "Confianza: 0.93\n",
      "Clase: 0\n",
      "Confianza: 0.34\n",
      "Clase: 39\n",
      "Speed: 2.4ms preprocess, 164.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 136.5ms\n",
      "Confianza: 0.93\n",
      "Clase: 0\n",
      "Confianza: 0.29\n",
      "Clase: 39\n",
      "Speed: 5.0ms preprocess, 136.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 123.7ms\n",
      "Confianza: 0.93\n",
      "Clase: 0\n",
      "Confianza: 0.31\n",
      "Clase: 39\n",
      "Speed: 2.3ms preprocess, 123.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 127.3ms\n",
      "Confianza: 0.93\n",
      "Clase: 0\n",
      "Confianza: 0.33\n",
      "Clase: 39\n",
      "Speed: 1.7ms preprocess, 127.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 126.0ms\n",
      "Confianza: 0.94\n",
      "Clase: 0\n",
      "Confianza: 0.35\n",
      "Clase: 39\n",
      "Speed: 2.3ms preprocess, 126.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 124.3ms\n",
      "Confianza: 0.93\n",
      "Clase: 0\n",
      "Confianza: 0.31\n",
      "Clase: 39\n",
      "Speed: 1.6ms preprocess, 124.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 136.3ms\n",
      "Confianza: 0.93\n",
      "Clase: 0\n",
      "Confianza: 0.27\n",
      "Clase: 39\n",
      "Speed: 1.8ms preprocess, 136.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 126.5ms\n",
      "Confianza: 0.93\n",
      "Clase: 0\n",
      "Confianza: 0.31\n",
      "Clase: 39\n",
      "Speed: 1.5ms preprocess, 126.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 128.4ms\n",
      "Confianza: 0.93\n",
      "Clase: 0\n",
      "Confianza: 0.32\n",
      "Clase: 39\n",
      "Speed: 2.3ms preprocess, 128.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 126.4ms\n",
      "Confianza: 0.93\n",
      "Clase: 0\n",
      "Confianza: 0.26\n",
      "Clase: 39\n",
      "Speed: 2.9ms preprocess, 126.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "# iniciar la camara y establecer resulocion de img\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "cap.set(3, 1080)\n",
    "\n",
    "cap.set(4, 1080)\n",
    "\n",
    "#carga del modelos yolo \n",
    "\n",
    "model = YOLO('yolo12n.pt')\n",
    "\n",
    "#clases que vamos a detectar\n",
    "\n",
    "classNames = list(objetos.values())\n",
    "\n",
    "#creamos un bucle para capturar la imagen de la camara y se lo pasamos al modelo\n",
    "\n",
    "while True:\n",
    "\n",
    "    success, img = cap.read() #lectura de la camara\n",
    "\n",
    "    results = model(img, stream=True) #pasamos la imagen al modelo\n",
    "\n",
    "    #ir iterando sobre los resultados\n",
    "\n",
    "    for r in results:\n",
    "\n",
    "        boxes = r.boxes #cajas detectadas\n",
    "\n",
    "        #iteramos sobre las cajas detectadas\n",
    "\n",
    "        for box in boxes:\n",
    "\n",
    "            x1, y1, x2, y2 = box.xyxy[0] #coordenadas de la caja\n",
    "\n",
    "            x1, y1, x2, y2 = map(int, [x1, y1, x2, y2]) #convertimos a enteros\n",
    "\n",
    "            #dibujar un rectangulo alrededor del objeto detectado\n",
    "\n",
    "            cv2.rectangle(img, (x1, y1), (x2, y2), (255, 0, 255), 3)\n",
    "\n",
    "            #calcular y mostrar la confianza en el objeto\n",
    "\n",
    "            confidence = math.ceil(box.conf[0] * 100) / 100 #confianza del modelo\n",
    "\n",
    "            print (f\"Confianza: {confidence}\")\n",
    "\n",
    "            #obtenemos el nimbre de la clase del objeto detectado\n",
    "\n",
    "            class_id = int(box.cls[0]) #id de la clase\n",
    "\n",
    "            print(f\"Clase: {class_id}\")\n",
    "\n",
    "            #mostramos el nombre de la clase y la confianza en la imagen\n",
    "\n",
    "            org = (x1, y1)\n",
    "\n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "            cv2.putText(img, f\"{classNames[class_id]} {confidence}\", org, font, 1, (255, 0, 0), 2)\n",
    "\n",
    "    #crear una ventana para mostrar la imagen\n",
    "\n",
    "    cv2.imshow(\"Deteccion de Objetos\", img)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'): #si se pulsa la tecla 'q' se sale del bucle\n",
    "\n",
    "        break\n",
    "\n",
    "    # liberar la camara y cerrar las ventanas\n",
    "\n",
    "cap.release()\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a591607b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "class ContadorPersonasMadrid:\n",
    "    def __init__(self):\n",
    "        self.model = YOLO('yolov8n.pt')\n",
    "        self.contador = 0\n",
    "        self.personas_contadas = set()\n",
    "        self.linea_conteo = None\n",
    "    def configurar_linea_conteo(self, frame):\n",
    "        \"\"\"Configurar línea de conteo invisible\"\"\"\n",
    "        height, width = frame.shape[:2]\n",
    "        self.linea_conteo = height // 2\n",
    "    def detectar_y_contar(self, frame):\n",
    "        \"\"\"Detectar personas y contarlas\"\"\"\n",
    "        resultados = self.model.track(frame, persist=True)\n",
    "        if self.linea_conteo is None:\n",
    "            self.configurar_linea_conteo(frame)\n",
    "        for resultado in resultados:\n",
    "            if resultado.boxes is not None:\n",
    "                for box in resultado.boxes:\n",
    "                    x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n",
    "                    clase_id = int(box.cls[0].cpu().numpy())\n",
    "                    confianza = box.conf[0].cpu().numpy()\n",
    "                    # Solo detectar personas (clase 0 en COCO)\n",
    "                    if clase_id == 0 and confianza > 0.5:\n",
    "                        persona_id = int(box.id[0].cpu().numpy()) if box.id is not None else hash((x1, y1, x2, y2))\n",
    "                        centro_y = int((y1 + y2) / 2)\n",
    "                        # Verificar si cruza la línea\n",
    "                        if (abs(centro_y - self.linea_conteo) < 20 and \n",
    "                            persona_id not in self.personas_contadas):\n",
    "                            self.personas_contadas.add(persona_id)\n",
    "                            self.contador += 1\n",
    "                        # Dibujar detección muy sutil\n",
    "                        cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 1)\n",
    "        return frame\n",
    "    def mostrar_contador(self, frame):\n",
    "        \"\"\"Mostrar contador discreto en esquina superior derecha\"\"\"\n",
    "        height, width = frame.shape[:2]\n",
    "        # Fondo semi-transparente pequeño\n",
    "        overlay = frame.copy()\n",
    "        cv2.rectangle(overlay, (width-150, 10), (width-10, 80), (0, 0, 0), -1)\n",
    "        frame = cv2.addWeighted(frame, 0.7, overlay, 0.3, 0)\n",
    "        # Texto del contador\n",
    "        cv2.putText(frame, f\"Madrid Callao\", (width-140, 30), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 0), 1)\n",
    "        cv2.putText(frame, f\"Personas: {self.contador}\", (width-140, 50), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "        cv2.putText(frame, f\"En vivo\", (width-140, 70), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 255, 0), 1)\n",
    "        return frame\n",
    "def main():\n",
    "    print(\"=== CONTADOR PERSONAS MADRID PLAZA DEL CALLAO ===\")\n",
    "    # URL extraída del código JavaScript que proporcionaste\n",
    "    stream_url = \"https://hd-auth.skylinewebcams.com/livee.m3u8?a=vlc3rldo2u9b3i6fr61e3ko6c1\"\n",
    "    print(f\"🎥 Conectando a Madrid Plaza del Callao...\")\n",
    "    print(f\"📍 Vista: Cine Callao, Palace FNAC y Metro Callao\")\n",
    "    contador = ContadorPersonasMadrid()\n",
    "    cap = cv2.VideoCapture(stream_url)\n",
    "    if not cap.isOpened():\n",
    "        print(\"❌ Error: No se pudo conectar al stream\")\n",
    "        print(\"💡 Soluciones:\")\n",
    "        print(\"- Verificar conexión a internet\")\n",
    "        print(\"- Instalar FFmpeg si no está instalado\")\n",
    "        print(\"- La URL podría haber cambiado\")\n",
    "        return\n",
    "    print(\"✅ Conectado a Madrid Plaza del Callao\")\n",
    "    print(\"👥 Contando personas en tiempo real...\")\n",
    "    print(\"Presiona 'q' para salir\")\n",
    "    frame_count = 0\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"⚠️ Perdida de conexión\")\n",
    "            break\n",
    "        frame_count += 1\n",
    "        # Procesar cada 2 frames para mejor rendimiento\n",
    "        if frame_count % 2 == 0:\n",
    "            frame = contador.detectar_y_contar(frame)\n",
    "        # Mostrar contador discreto\n",
    "        frame = contador.mostrar_contador(frame)\n",
    "        # Mostrar video\n",
    "        cv2.imshow('Madrid Plaza del Callao - Contador Personas', frame)\n",
    "        # Salir con 'q'\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(f\"\\n📊 Sesión finalizada\")\n",
    "    print(f\"👥 Total de personas contadas: {contador.contador}\")\n",
    "    print(f\"📍 Ubicación: Plaza del Callao, Madrid\")\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
